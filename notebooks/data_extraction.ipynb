{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "Joeri R. Hermans                    \n",
    "*Departement of Data Science & Knowledge Engineering*          \n",
    "*Maastricht University, The Netherlands*        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we mainly consider the extraction of the data from numpy files, and preprocess them to a more desireable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelValZpTT_1500_13_nevents9000\n",
      "RelValQQH1352T_13.nevents9000\n",
      "RelValRSKKGluon_m3000GeV_13_nevents9000\n",
      "RelValSMS-T1tttt_mGl-1500_mLSP-100_13_GEN-SIM-RECO_evt1750\n",
      "RelValSMS-T1tttt_mGl-1500_mLSP-100_13_nevents9000\n",
      "RelValH125GGgluonfusion_13.nevents9000\n",
      "RelValQCD_Pt_600_800_13_nevents9000\n",
      "RelValH125GGgluonfusion_13_GEN-SIM-RECO_evt4500\n",
      "RelValRSGravitonToGaGa_13_GEN-SIM-RECO_evt2000\n",
      "RelValPhiToMuMu_13_GEN-SIM-RECO_evt4358\n",
      "RelValWjet_Pt_3000_3500_13_GEN-SIM-RECO_evt3150\n",
      "noise\n",
      "RelValHiggs200ChargedTaus_13_nevents9000\n",
      "RelValDisplacedSUSY_stopToBottom_M_300_1000mm_13_GEN-SIM-RECO_evt3500\n",
      "RelValWjet_Pt_80_120_13.nevents9000\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"../data/\"\n",
    "track_types = os.listdir(data_directory)\n",
    "\n",
    "# List the track types.\n",
    "for e in track_types:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal attributes among all events: True\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "\n",
    "# The noise event needs to be considered at a later time.\n",
    "track_types.remove('noise')\n",
    "\n",
    "# Fetch the columns names from the events.\n",
    "for e in track_types:\n",
    "    track_files = os.listdir(data_directory + e)\n",
    "    track_file = track_files[0]\n",
    "    data = np.load(data_directory + e + \"/\" + track_file)\n",
    "    columns.append(data.dtype.names)\n",
    "\n",
    "# Check if the columns have the same attributes.\n",
    "num_columns = len(columns)\n",
    "c = columns[0]\n",
    "equal = True\n",
    "for i in range(1, num_columns):\n",
    "    equal &= (c == columns[i])\n",
    "    if not equal:\n",
    "        break\n",
    "        \n",
    "print(\"Equal attributes among all events: \" + str(equal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might have noticed that the data that was provided to us contains simulated data. In order to have a clean comparison of simulated and real data, we maintain two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulated_data = [t for t in track_types if 'SIM' in t]\n",
    "real_data = [t for t in track_types if 'SIM' not in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema definition\n",
    "\n",
    "We store the data in the Avro format, which is a binary serialized row-based format. However, before we do that, we first need to specify a schema in order to describe the contents of the file-format.\n",
    "\n",
    "**Note:** Collisions are grouped by: (run, event, luminosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"namespace\": \"trackml.cern.ch\",\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Tracks\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"track_id\", \"type\": \"int\"},\n",
    "        {\"name\": \"collision_id\", \"type\": \"string\"}\n",
    "        {\"name\": \"run\", \"type\": \"int\"},\n",
    "        {\"name\": \"event\", \"type\": \"int\"},\n",
    "        {\"name\": \"luminosity\", \"type\": \"int\"},\n",
    "        {\"name\": \"track_type\", \"type\": \"string\"},\n",
    "        {\"name\": \"charge\", \"type\": \"int\"},\n",
    "        {\"name\": \"ndof\", \"type\": \"int\"},\n",
    "        {\"name\": \"qoverp\", \"type\": \"double\"},\n",
    "        {\"name\": \"theta\", \"type\": \"double\"},\n",
    "        {\"name\": \"dxy\", \"type\": \"double\"},\n",
    "        {\"name\": \"d0\", \"type\": \"double\"},\n",
    "        {\"name\": \"dsz\", \"type\": \"double\"},\n",
    "        {\"name\": \"dz\", \"type\": \"double\"},\n",
    "        {\"name\": \"p\", \"type\": \"double\"},\n",
    "        {\"name\": \"pt\", \"type\": \"double\"},\n",
    "        {\"name\": \"px\", \"type\": \"double\"},\n",
    "        {\"name\": \"py\", \"type\": \"double\"},\n",
    "        {\"name\": \"pz\", \"type\": \"double\"},\n",
    "        {\"name\": \"eta\", \"type\": \"double\"},\n",
    "        {\"name\": \"phi\", \"type\": \"double\"},\n",
    "        {\"name\": \"vx\", \"type\": \"double\"},\n",
    "        {\"name\": \"vy\", \"type\": \"double\"},\n",
    "        {\"name\": \"vz\", \"type\": \"double\"},\n",
    "        {\"name\": \"num_background_hits\", \"type\": \"int\"},\n",
    "        {\"name\": \"num_track_hits\", \"type\": \"int\"},\n",
    "        # Define the structure of the background hits.\n",
    "        {\"name\": \"background_hits\", \"type\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"background_hit\",\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"x\", \"type\": \"double\"},\n",
    "                    {\"name\": \"y\", \"type\": \"double\"},\n",
    "                    {\"name\": \"z\", \"type\": \"double\"}\n",
    "                ]\n",
    "            }\n",
    "        }},\n",
    "        # Define the structure of the track hits.\n",
    "        {\"name\": \"track_hits\", \"type\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"record\",\n",
    "                \"name\": \"track_hit\",\n",
    "                \"fields\": [\n",
    "                    {\"name\": \"x\", \"type\": \"double\"},\n",
    "                    {\"name\": \"y\", \"type\": \"double\"},\n",
    "                    {\"name\": \"z\", \"type\": \"double\"}\n",
    "                ]\n",
    "            }\n",
    "        }}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Construction\n",
    "\n",
    "Now the schema is available for all track types described above, we can write the tracks to an output file which can be used on the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_hits(record):\n",
    "    hits = []\n",
    "    \n",
    "    # Define the maximum number of hits (due to the given format).\n",
    "    max_silicon_pixel_hits = 5\n",
    "    max_silicon_strip_hits = 50\n",
    "    \n",
    "    # Extract hits from the silicon pixel detector.\n",
    "    for i in range(0, max_silicon_pixel_hits):\n",
    "        index = str(i)\n",
    "        x = record['pix_' + index + '_x']\n",
    "        y = record['pix_' + index + '_y']\n",
    "        z = record['pix_' + index + '_z']\n",
    "        if x == 0.0 and y == 0.0 and z == 0.0:\n",
    "            break\n",
    "        # Append the hit.\n",
    "        hits.append({'x': x, 'y': y, 'z': z})\n",
    "    # Extract hits from the silicon strip detector.\n",
    "    for i in range(0, max_silicon_strip_hits):\n",
    "        index = str(i)\n",
    "        x = record['sis_' + index + '_x']\n",
    "        y = record['sis_' + index + '_y']\n",
    "        z = record['sis_' + index + '_z']\n",
    "        if x == 0.0 and y == 0.0 and z == 0.0:\n",
    "            break\n",
    "        # Append the hit.\n",
    "        hits.append({'x': x, 'y': y, 'z': z})\n",
    "    \n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_record(record, track_type):\n",
    "    r = {}\n",
    "    \n",
    "    # Extract the detector hits.\n",
    "    track_hits = extract_hits(record)\n",
    "    background_hits = [] # No background hits\n",
    "    # Extrac track parameters.\n",
    "    r['track_id']    = int(record['TrackId'])\n",
    "    r['run']         = int(record['run'])\n",
    "    r['event']       = int(record['evt'])\n",
    "    r['luminosity']  = int(record['lumi'])\n",
    "    r['collision_id'] = str(r['run']) + \"-\" + str(r['event']) + \"-\" + str(r['luminosity'])\n",
    "    r['track_type']  = track_type\n",
    "    r['charge']      = int(record['charge'])\n",
    "    r['ndof']        = int(record['ndof'])     \n",
    "    r['qoverp']      = record['qoverp']\n",
    "    r['theta']       = record['theta']\n",
    "    r['dxy']         = record['dxy']\n",
    "    r['d0']          = record['d0']\n",
    "    r['dsz']         = record['dsz']\n",
    "    r['dz']          = record['dz']\n",
    "    r['p']           = record['p']\n",
    "    r['pt']          = record['pt']\n",
    "    r['px']          = record['px']\n",
    "    r['py']          = record['py']\n",
    "    r['pz']          = record['pz']\n",
    "    r['eta']         = record['eta']\n",
    "    r['phi']         = record['phi']\n",
    "    r['vx']          = record['vx']\n",
    "    r['vy']          = record['vy']\n",
    "    r['vz']          = record['vz']\n",
    "    # Add the detector hits.\n",
    "    r['background_hits'] = background_hits\n",
    "    r['num_background_hits'] = len(background_hits)\n",
    "    r['track_hits'] = track_hits\n",
    "    r['num_track_hits'] = len(track_hits)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_path(path):\n",
    "    # Initialize the records buffer.\n",
    "    records_buffer = []\n",
    "    # Obtain the record type from the path.\n",
    "    t = path.split('/')[-2]\n",
    "    # Load the data from the specified path.\n",
    "    data = np.load(path)\n",
    "    for r in data:\n",
    "        # Add the record to the buffer.\n",
    "        records_buffer.append(create_record(r, t))\n",
    "        \n",
    "    return records_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_records(records):\n",
    "    for record in records:\n",
    "        writer.write(record)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fastavro.writer import Writer\n",
    "from fastavro.reader import SYNC_SIZE\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Lock\n",
    "\n",
    "from contextlib import closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain all file paths, this will benefit the parallelism.\n",
    "paths = []\n",
    "\n",
    "for t in track_types:\n",
    "    path = data_directory + t + '/'\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        paths.append(path + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0/24356\n",
      "Processed: 100/24356\n",
      "Processed: 200/24356"
     ]
    }
   ],
   "source": [
    "records_buffer = []\n",
    "buffer_size = 0\n",
    "max_buffer_size = 100\n",
    "\n",
    "num_paths = len(paths)\n",
    "path_index = 0\n",
    "\n",
    "print(\"Processed: \" + str(path_index) + \"/\" + str(num_paths))\n",
    "with open('tracks.avro', 'wb') as out:\n",
    "    # Allocate a fastavro writer.\n",
    "    writer = Writer(out, schema, sync_interval=10000 * SYNC_SIZE)\n",
    "    # Process all paths, and flush buffer periodically.\n",
    "    for p in paths:\n",
    "        path_records = read_path(p)\n",
    "        records_buffer.extend(path_records)\n",
    "        buffer_size += 1\n",
    "        path_index += 1\n",
    "        if buffer_size >= max_buffer_size:\n",
    "            print(\"Processed: \" + str(path_index) + \"/\" + str(num_paths))\n",
    "            write_records(records_buffer)\n",
    "            del records_buffer\n",
    "            records_buffer = []\n",
    "            buffer_size = 0\n",
    "    # Check if we have a non-empy buffer.\n",
    "    if buffer_size > 0:\n",
    "        write_records(records_buffer)\n",
    "        del records_buffer\n",
    "        records_buffer = []\n",
    "        buffer_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
